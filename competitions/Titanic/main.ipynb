{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ea71e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: nvidia-smi\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0604bfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0e12a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 学習データ、テストデータの読み込み\n",
    "# kaggle環境で実行する場合\n",
    "# train = pd.read_csv('../input/titanic/train.csv')\n",
    "# test = pd.read_csv('../input/titanic/test.csv')\n",
    "# ローカル環境で実行する場合\n",
    "train = pd.read_csv('../../datasets/titanic/train.csv')\n",
    "test = pd.read_csv('../../datasets/titanic/test.csv')\n",
    "\n",
    "# 学習データを特徴量と目的変数に分ける\n",
    "train_x = train.drop(['Survived'], axis=1)\n",
    "train_y = train['Survived']\n",
    "\n",
    "test_x = test.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6356e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass                                          Name     Sex   Age  SibSp  \\\n",
       "0       3                              Kelly, Mr. James    male  34.5      0   \n",
       "1       3              Wilkes, Mrs. James (Ellen Needs)  female  47.0      1   \n",
       "2       2                     Myles, Mr. Thomas Francis    male  62.0      0   \n",
       "3       3                              Wirz, Mr. Albert    male  27.0      0   \n",
       "4       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female  22.0      1   \n",
       "\n",
       "   Parch   Ticket     Fare Cabin Embarked  \n",
       "0      0   330911   7.8292   NaN        Q  \n",
       "1      0   363272   7.0000   NaN        S  \n",
       "2      0   240276   9.6875   NaN        Q  \n",
       "3      0   315154   8.6625   NaN        S  \n",
       "4      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 変数PassengerIdを除外する\n",
    "train_x = train_x.drop(['PassengerId'], axis=1)\n",
    "test_x = test_x.drop(['PassengerId'], axis=1)\n",
    "test_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a20b22c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       "0       3    male  34.5      0      0   7.8292        Q\n",
       "1       3  female  47.0      1      0   7.0000        S\n",
       "2       2    male  62.0      0      0   9.6875        Q\n",
       "3       3    male  27.0      0      0   8.6625        S\n",
       "4       3  female  22.0      1      1  12.2875        S"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 変数Name, Ticket, Cabinを除外\n",
    "train_x = train_x.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n",
    "test_x = test_x.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n",
    "test_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fee70ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# それぞれのカテゴリ変数にLabel encodingを適用する\n",
    "for c in ['Sex', 'Embarked']:\n",
    "    # 学習データに基づいてどう変換するかを定める\n",
    "    le = LabelEncoder()\n",
    "    le.fit(train_x[c].fillna('NA'))\n",
    "\n",
    "    # 学習データ、テストデータを変換する\n",
    "    train_x[c] = le.transform(train_x[c].fillna('NA'))\n",
    "    test_x[c] = le.transform(test_x[c].fillna('NA'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2607b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x.head(100)\n",
    "# csvに書き出し\n",
    "test_x.to_csv('test_x.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3246263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 勾配ブースティングのライブラリをインポート\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# モデルの作成および学習データを与えての学習\n",
    "model = XGBClassifier(n_estimators=100, random_state=71)\n",
    "model.fit(train_x, train_y)\n",
    "\n",
    "# テストデータの予測値を確率で出力する\n",
    "pred = model.predict_proba(test_x)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44038bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# 予測値を2値に変換する\n",
    "pred_label = np.where(pred > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1db7ebda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35f75d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提出用のファイルの作成\n",
    "submission = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived': pred_label})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dafa72de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex   Age  SibSp  Parch     Fare  Embarked\n",
       "0       3    1  22.0      1      0   7.2500         3\n",
       "1       1    0  38.0      1      0  71.2833         0\n",
       "2       3    0  26.0      0      0   7.9250         3\n",
       "3       1    0  35.0      1      0  53.1000         3\n",
       "4       3    1  35.0      0      0   8.0500         3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb0efd8",
   "metadata": {},
   "source": [
    "# クロスバリデーション"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d591353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.4405, accuracy: 0.8227\n",
      "[0.8161434977578476, 0.8116591928251121, 0.8295964125560538, 0.8333333333333334]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# 各foldのスコアを保存するリスト\n",
    "scores_accuracy = []\n",
    "scores_logloss = []\n",
    "\n",
    "# クロスバリデーションを行う\n",
    "# 学習データを4つに分割し、うち一つをバリデーションデータとすることを、バリデーションデータを変えて繰り返す\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=71)\n",
    "for tr_idx, va_idx, in kf.split(train_x):\n",
    "    # 学習データを学習データとバリデーションデータに分ける\n",
    "    # tr_idx, va_idxは分割後のindex\n",
    "    tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n",
    "    tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n",
    "    \n",
    "    # モデルの学習を行う\n",
    "    model = XGBClassifier(n_estimators = 20, random_state=71)\n",
    "    model.fit(tr_x, tr_y)\n",
    "    \n",
    "    # バリデーションデータの予測値を確率で出力する\n",
    "    va_pred = model.predict_proba(va_x)[:,1]\n",
    "\n",
    "    # バリデーションデータのスコアを計算する\n",
    "    logloss = log_loss(va_y, va_pred)\n",
    "    accuracy = accuracy_score(va_y, va_pred > 0.5)\n",
    "\n",
    "    # 結果をリストに追加\n",
    "    scores_accuracy.append(accuracy)\n",
    "    scores_logloss.append(logloss)\n",
    "\n",
    "# 各foldのスコアの平均を出力する　\n",
    "mean_of_logloss = np.mean(scores_logloss)\n",
    "mean_of_acc = np.mean(scores_accuracy)\n",
    "print(f'logloss: {mean_of_logloss:.4f}, accuracy: {mean_of_acc:.4f}')\n",
    "print(scores_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35eae415",
   "metadata": {},
   "source": [
    "# モデルのチューニング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "315a0c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth: 3, min_child_weight: 2.0, learning_rate: 0.3\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "# チューニング候補とするパラメータを準備する\n",
    "param_space = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_child_weight': [1.0, 2.0, 4.0],\n",
    "    'learning_rate': [0.01, 0.1, 0.3]\n",
    "}\n",
    "\n",
    "# 探索するハイパーパラメータの組み合わせ, productはデカルト積を返す\n",
    "param_combinations = list(itertools.product(param_space['max_depth'], param_space['min_child_weight'], param_space['learning_rate']))\n",
    "\n",
    "# 各パラメータの組み合わせ、それに対するスコアを保持するリスト\n",
    "params = []\n",
    "scores = []\n",
    "# 各パラメータの組み合わせごとにクロスバリデーションで評価を行う\n",
    "for max_depth, min_child_weight, learning_rate in param_combinations:\n",
    "    scores_folds = []\n",
    "\n",
    "    kf = KFold(n_splits=4, shuffle=True, random_state=71)\n",
    "    for tr_idx, va_idx, in kf.split(train_x):\n",
    "        # 学習データを学習データとバリデーションデータに分ける\n",
    "        # tr_idx, va_idxは分割後のindex\n",
    "        tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n",
    "        tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n",
    "        \n",
    "        # モデルの学習を行う\n",
    "        model = XGBClassifier(n_estimators = 20, random_state=71, \n",
    "                              max_depth=max_depth, min_child_weight=min_child_weight, learning_rate=learning_rate)\n",
    "        model.fit(tr_x, tr_y)\n",
    "        \n",
    "        # バリデーションデータの予測値を確率で出力する\n",
    "        va_pred = model.predict_proba(va_x)[:,1]\n",
    "        logloss = log_loss(va_y, va_pred)\n",
    "        scores_folds.append(logloss)\n",
    "    \n",
    "    # 各foldのスコアを平均する　\n",
    "    score_mean = np.mean(scores_folds)\n",
    "    \n",
    "    # パラメータの組み合わせ、それに対するスコアを保持する\n",
    "    params.append((max_depth, min_child_weight, learning_rate))\n",
    "    scores.append(score_mean)\n",
    "\n",
    "# 最もスコアが良いものをベストパラメータとする\n",
    "best_idx = np.argsort(scores)[0]\n",
    "best_param = params[best_idx]\n",
    "print(f'max_depth: {best_param[0]}, min_child_weight: {best_param[1]}, learning_rate: {best_param[2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6e7c84a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2.0, 0.3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_param"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f45f6b8",
   "metadata": {},
   "source": [
    "# アンサンブル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fcfeeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shosei/anaconda3/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder(sparse=False, sparse_output=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(sparse=False, sparse_output=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneHotEncoder(sparse=False, sparse_output=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ロジスティック回帰モデル用のデータを用意\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 元データをコピーする\n",
    "train_x2 = train.drop(['Survived'], axis=1)\n",
    "test_x2 = test.copy()\n",
    "\n",
    "# 変数PassengerIdを除外する\n",
    "train_x2 = train_x2.drop(['PassengerId'], axis=1)\n",
    "test_x2= test_x2.drop(['PassengerId'], axis=1)\n",
    "\n",
    "# 変数Name, Ticket, Cabinを除外する\n",
    "train_x2 = train_x2.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n",
    "test_x2 = test_x2.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n",
    "\n",
    "# one-hot encodingを行う\n",
    "cat_cols = ['Sex', 'Embarked', 'Pclass']\n",
    "ohe = OneHotEncoder(categories='auto', sparse=False)\n",
    "ohe.fit(train_x2[cat_cols].fillna('NA'))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4cc936de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sex_female',\n",
       " 'Sex_male',\n",
       " 'Embarked_C',\n",
       " 'Embarked_NA',\n",
       " 'Embarked_Q',\n",
       " 'Embarked_S',\n",
       " 'Pclass_1',\n",
       " 'Pclass_2',\n",
       " 'Pclass_3']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot encodingのダミー変数の列名を作成する\n",
    "ohe_columns = []\n",
    "for i, c in enumerate(cat_cols):\n",
    "    ohe_columns += [f'{c}_{v}' for v in ohe.categories_[i]]\n",
    "ohe_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1bcb3f6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Sex', 'Embarked', 'Pclass'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# one-hot encodingによる変換を行う\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m ohe_train_x2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(ohe\u001b[38;5;241m.\u001b[39mtransform(\u001b[43mtrain_x2\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcat_cols\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNA\u001b[39m\u001b[38;5;124m'\u001b[39m)), columns\u001b[38;5;241m=\u001b[39mohe_columns)\n\u001b[1;32m      3\u001b[0m ohe_test_x2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(ohe\u001b[38;5;241m.\u001b[39mtransform(test_x2[cat_cols]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNA\u001b[39m\u001b[38;5;124m'\u001b[39m)), columns\u001b[38;5;241m=\u001b[39mohe_columns)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# one-hot encoding済みの変数を除外する\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/frame.py:3813\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3812\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3813\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3815\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/indexes/base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6067\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6070\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6072\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6074\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/indexes/base.py:6130\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[1;32m   6129\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 6130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6132\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   6133\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['Sex', 'Embarked', 'Pclass'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# one-hot encodingによる変換を行う\n",
    "ohe_train_x2 = pd.DataFrame(ohe.transform(train_x2[cat_cols].fillna('NA')), columns=ohe_columns)\n",
    "ohe_test_x2 = pd.DataFrame(ohe.transform(test_x2[cat_cols].fillna('NA')), columns=ohe_columns)\n",
    "\n",
    "\n",
    "# one-hot encoding済みの変数を除外する\n",
    "train_x2 = train_x2.drop(cat_cols, axis=1)\n",
    "test_x2 = test_x2.drop(cat_cols, axis=1)\n",
    "\n",
    "# 結合する\n",
    "train_x2 = pd.concat([train_x2, ohe_train_x2], axis=1)\n",
    "test_x2 = pd.concat([test_x2, ohe_test_x2], axis=1)\n",
    "\n",
    "train_x2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b49ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# xgboost\n",
    "model_xgb = XGBClassifier(n_estimators=20, random_state=71, \n",
    "                          max_depth=best_param[0], min_child_weight=best_param[1], learning_rate=best_param[2])\n",
    "model_xgb.fit(train_x, train_y)\n",
    "pred_xgb = model_xgb.predict_proba(test_x)[:,1]\n",
    "\n",
    "# ロジスティック回帰モデル\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
